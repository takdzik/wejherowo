{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from perceiver_pytorch import PerceiverIO\n",
    "\n",
    "# Dataset\n",
    "class CarDataset(Dataset):\n",
    "    def __init__(self, json_path, image_dir, transform=None, num_images=12, use_images=True, use_tabular=True):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.num_images = num_images\n",
    "        self.use_images = use_images\n",
    "        self.use_tabular = use_tabular\n",
    "\n",
    "        print(f\"Tworzę CarDataset: use_images={use_images}, use_tabular={use_tabular}\")\n",
    "\n",
    "        # Wczytaj dane JSON\n",
    "        self.data = pd.read_json(json_path, lines=True)\n",
    "\n",
    "        # Filtruj dane z przynajmniej jednym zdjęciem\n",
    "        self.samples = []\n",
    "        for _, row in self.data.iterrows():\n",
    "            car_id = str(row[\"id\"])  # Używamy pola `id` do identyfikacji ofert\n",
    "            has_images = any(\n",
    "                Path(self.image_dir, f\"{car_id}_{i}.jpg\").exists() for i in range(1, self.num_images + 1)\n",
    "            )\n",
    "            if (self.use_images and has_images) or not self.use_images:\n",
    "                # Konwersja danych tabelarycznych na numeryczne\n",
    "                if self.use_tabular:\n",
    "                    try:\n",
    "                        tabular_data = row.drop([\"url\", \"cena\", \"id\"]).astype(float).values\n",
    "                    except Exception as e:\n",
    "                        print(f\"Błąd w danych tabelarycznych: {row}\")\n",
    "                        raise e\n",
    "\n",
    "                self.samples.append({\n",
    "                    \"id\": car_id,\n",
    "                    \"price\": row[\"cena\"],  # Cena samochodu\n",
    "                    \"tabular_data\": torch.tensor(tabular_data, dtype=torch.float32) if self.use_tabular else None,\n",
    "                    \"url\": row[\"url\"] if \"url\" in row else None\n",
    "                })\n",
    "\n",
    "        print(f\"Dataset: Wczytano {len(self.samples)} rekordów.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        car_id = sample[\"id\"]\n",
    "        price = torch.tensor(sample[\"price\"], dtype=torch.float32)\n",
    "        tabular_data = sample[\"tabular_data\"]\n",
    "        url = sample[\"url\"]\n",
    "\n",
    "        images = None\n",
    "        if self.use_images:\n",
    "            # Załaduj zdjęcia\n",
    "            images = []\n",
    "            for i in range(1, self.num_images + 1):\n",
    "                image_path = Path(self.image_dir, f\"{car_id}_{i}.jpg\")\n",
    "                if image_path.exists():\n",
    "                    img = Image.open(image_path).convert(\"RGB\")\n",
    "                    if self.transform:\n",
    "                        img = self.transform(img)\n",
    "                    images.append(img)\n",
    "\n",
    "            while len(images) < self.num_images:\n",
    "                images.append(images[-1])\n",
    "\n",
    "            images = images[:self.num_images]\n",
    "            images = torch.stack(images)  # [NUM_IMAGES, C, H, W]\n",
    "\n",
    "        return images, tabular_data, price, url\n",
    "\n",
    "# Model\n",
    "class MultimodalPerceiver(nn.Module):\n",
    "    def __init__(self, image_dim=(3, 140, 100), tabular_dim=3, latent_dim=512, num_latents=256, num_images=12, use_images=True, use_tabular=True):\n",
    "        super(MultimodalPerceiver, self).__init__()\n",
    "        self.use_images = use_images\n",
    "        self.use_tabular = use_tabular\n",
    "        self.num_images = num_images\n",
    "\n",
    "        # Perceiver IO\n",
    "        self.perceiver = PerceiverIO(\n",
    "            dim=latent_dim,\n",
    "            queries_dim=1,  # Jedna wartość wyjściowa dla ceny\n",
    "            logits_dim=latent_dim,   # Przepuszczamy przez latent_dim\n",
    "            depth=6,        # Liczba warstw\n",
    "            num_latents=num_latents,\n",
    "            latent_dim=latent_dim\n",
    "        )\n",
    "\n",
    "        # Embeddingi dla obrazów\n",
    "        if self.use_images:\n",
    "            self.image_embedding = nn.Sequential(\n",
    "                nn.Conv2d(image_dim[0], latent_dim, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.AdaptiveAvgPool2d((1, 1)),\n",
    "                nn.Flatten()\n",
    "            )\n",
    "\n",
    "        # Embeddingi dla danych tabelarycznych\n",
    "        if self.use_tabular:\n",
    "            self.tabular_embedding = nn.Sequential(\n",
    "                nn.Linear(tabular_dim, latent_dim),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "\n",
    "        # Warstwa redukująca wymiar cech połączonych\n",
    "        if self.use_images and self.use_tabular:\n",
    "            self.combined_linear = nn.Linear(latent_dim * 2, latent_dim)\n",
    "\n",
    "        # Warstwa wyjściowa regresji\n",
    "        self.output_layer = nn.Linear(latent_dim, 1)\n",
    "\n",
    "    def forward(self, images=None, tabular_data=None):\n",
    "        image_features = None\n",
    "        tabular_features = None\n",
    "\n",
    "        # Przetwarzanie obrazów\n",
    "        if self.use_images and images is not None:\n",
    "            batch_size = images.size(0)\n",
    "            image_features = []\n",
    "            for i in range(self.num_images):\n",
    "                img_emb = self.image_embedding(images[:, i, :, :, :])  # [BATCH_SIZE, LATENT_DIM]\n",
    "                image_features.append(img_emb)\n",
    "            image_features = torch.stack(image_features, dim=1)  # [BATCH_SIZE, NUM_IMAGES, LATENT_DIM]\n",
    "            image_features = image_features.mean(dim=1)  # Uśrednianie po obrazach\n",
    "\n",
    "        # Przetwarzanie danych tabelarycznych\n",
    "        if self.use_tabular and tabular_data is not None:\n",
    "            tabular_features = self.tabular_embedding(tabular_data)  # [BATCH_SIZE, LATENT_DIM]\n",
    "\n",
    "        # Łączenie cech\n",
    "        if self.use_images and self.use_tabular:\n",
    "            combined_features = torch.cat((image_features, tabular_features), dim=1)  # [BATCH_SIZE, LATENT_DIM * 2]\n",
    "            combined_features = self.combined_linear(combined_features)  # Redukcja do [BATCH_SIZE, LATENT_DIM]\n",
    "        elif self.use_images:\n",
    "            combined_features = image_features\n",
    "        elif self.use_tabular:\n",
    "            combined_features = tabular_features\n",
    "\n",
    "        # Dodanie wymiaru sekwencji\n",
    "        combined_features = combined_features.unsqueeze(1)  # [BATCH_SIZE, 1, LATENT_DIM]\n",
    "\n",
    "        # Przepuszczanie przez Perceiver IO\n",
    "        perceiver_output = self.perceiver(combined_features)  # [BATCH_SIZE, num_latents, 1]\n",
    "\n",
    "        # Uśrednianie po num_latents\n",
    "        perceiver_output = perceiver_output.mean(dim=1)  # [BATCH_SIZE, 1]\n",
    "\n",
    "        # Wyjście ostateczne: [BATCH_SIZE, 1]\n",
    "        output = self.output_layer(perceiver_output)  # [BATCH_SIZE, 1]\n",
    "        return output.squeeze(1)  # [BATCH_SIZE]\n",
    "\n",
    "\n",
    "# Trening\n",
    "def train_model(json_path, image_dir, model, criterion, optimizer, num_epochs=10, batch_size=16, use_images=True, use_tabular=True):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((140, 100)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    dataset = CarDataset(json_path=json_path, image_dir=image_dir, transform=transform, use_images=use_images, use_tabular=use_tabular)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        start_time_epoch = time.time()\n",
    "\n",
    "        for i, (images, tabular_data, prices, urls) in enumerate(dataloader):\n",
    "            iter_start_time = time.time()\n",
    "\n",
    "            images = images.to(DEVICE) if images is not None else None\n",
    "            tabular_data = tabular_data.to(DEVICE) if tabular_data is not None else None\n",
    "            prices = prices.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images=images, tabular_data=tabular_data)\n",
    "            loss = criterion(outputs, prices)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            iter_time = time.time() - iter_start_time\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            print(f\"Iteracja {i+1}/{len(dataloader)}, Loss: {loss.item():.4f}, Time: {iter_time:.2f}s\")\n",
    "\n",
    "        epoch_time = time.time() - start_time_epoch\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/len(dataloader):.4f}, Time: {epoch_time:.2f}s\")\n",
    "\n",
    "    # Zapis modelu\n",
    "    input_config = f\"images-{use_images}_tabular-{use_tabular}\"\n",
    "    model_name = f\"car_price_predictor_{input_config}.pth\"\n",
    "    model_path = os.path.join(\"../models\", model_name)\n",
    "    os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Model zapisany w: {model_path}\")\n",
    "\n",
    "# Parametry\n",
    "JSON_PATH = \"../data/clean_data_train_01.json\"\n",
    "IMAGE_DIR = \"../data/images/\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Model, funkcja kosztu, optymalizator\n",
    "tabular_dim = len(CarDataset(json_path=JSON_PATH, image_dir=IMAGE_DIR, use_images=False).samples[0][\"tabular_data\"])\n",
    "model = MultimodalPerceiver(image_dim=(3, 140, 100), tabular_dim=tabular_dim, latent_dim=512, num_images=12, use_images=True, use_tabular=True).to(DEVICE)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Trenowanie\n",
    "train_model(JSON_PATH, IMAGE_DIR, model, criterion, optimizer, num_epochs=10, batch_size=16, use_images=True, use_tabular=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path, image_dim=(3, 140, 100), tabular_dim=3, latent_dim=512, num_latents=256, num_images=12, use_images=True, use_tabular=True):\n",
    "    \"\"\"\n",
    "    Ładuje zapisany model z pliku.\n",
    "    \n",
    "    Args:\n",
    "        model_path (str): Ścieżka do pliku modelu.\n",
    "        image_dim (tuple): Wymiary wejściowych obrazów.\n",
    "        tabular_dim (int): Wymiar danych tabelarycznych.\n",
    "        latent_dim (int): Wymiar latentny modelu.\n",
    "        num_latents (int): Liczba latentów w Perceiver IO.\n",
    "        num_images (int): Maksymalna liczba obrazów na ofertę.\n",
    "        use_images (bool): Czy używać danych obrazowych.\n",
    "        use_tabular (bool): Czy używać danych tabelarycznych.\n",
    "\n",
    "    Returns:\n",
    "        torch.nn.Module: Załadowany model.\n",
    "    \"\"\"\n",
    "    model = MultimodalPerceiver(\n",
    "        image_dim=image_dim,\n",
    "        tabular_dim=tabular_dim,\n",
    "        latent_dim=latent_dim,\n",
    "        num_latents=num_latents,\n",
    "        num_images=num_images,\n",
    "        use_images=use_images,\n",
    "        use_tabular=use_tabular\n",
    "    ).to(DEVICE)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "    model.eval()\n",
    "    print(f\"Model załadowany z: {model_path}\")\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, test_json_path, image_dir, batch_size=16, use_images=True, use_tabular=True):\n",
    "    \"\"\"\n",
    "    Przeprowadza ewaluację modelu na danych testowych.\n",
    "    \n",
    "    Args:\n",
    "        model (torch.nn.Module): Wytrenowany model do ewaluacji.\n",
    "        test_json_path (str): Ścieżka do pliku JSON z danymi testowymi.\n",
    "        image_dir (str): Katalog z obrazami.\n",
    "        batch_size (int): Rozmiar batcha.\n",
    "        use_images (bool): Czy używać danych obrazowych.\n",
    "        use_tabular (bool): Czy używać danych tabelarycznych.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Średni błąd kwadratowy (MSE) i średni błąd procentowy (MAPE) na danych testowych.\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((140, 100)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Przygotowanie danych testowych\n",
    "    test_dataset = CarDataset(\n",
    "        json_path=test_json_path,\n",
    "        image_dir=image_dir,\n",
    "        transform=transform,\n",
    "        use_images=use_images,\n",
    "        use_tabular=use_tabular\n",
    "    )\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Ewaluacja modelu\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_percentage_error = 0\n",
    "    total_samples = 0\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, tabular_data, prices, urls in test_loader:\n",
    "            images = images.to(DEVICE) if images is not None else None\n",
    "            tabular_data = tabular_data.to(DEVICE) if tabular_data is not None else None\n",
    "            prices = prices.to(DEVICE)\n",
    "\n",
    "            # Przewidywanie i obliczanie błędów\n",
    "            outputs = model(images=images, tabular_data=tabular_data)\n",
    "            loss = criterion(outputs, prices)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Obliczanie błędu procentowego\n",
    "            absolute_percentage_error = torch.abs((outputs - prices) / prices) * 100\n",
    "            total_percentage_error += absolute_percentage_error.sum().item()\n",
    "            total_samples += len(prices)\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    avg_percentage_error = total_percentage_error / total_samples\n",
    "    print(f\"Średni błąd kwadratowy (MSE) na danych testowych: {avg_loss:.4f}\")\n",
    "    print(f\"Średni błąd procentowy (MAPE) na danych testowych: {avg_percentage_error:.2f}%\")\n",
    "    return avg_loss, avg_percentage_error\n",
    "\n",
    "\n",
    "# Ścieżki do danych testowych i modelu\n",
    "TEST_JSON_PATH = \"../data/clean_data_test_01.json\"\n",
    "IMAGE_DIR = \"../data/images/\"\n",
    "MODEL_PATH = \"../models/car_price_predictor_images-tabular.pth\"\n",
    "\n",
    "# Ładowanie modelu\n",
    "#tabular_dim = len(CarDataset(json_path=TEST_JSON_PATH, image_dir=IMAGE_DIR, use_images=False).samples[0][\"tabular_data\"])\n",
    "model = load_model(\n",
    "    model_path=MODEL_PATH,\n",
    "    image_dim=(3, 140, 100),\n",
    "    tabular_dim=tabular_dim,\n",
    "    latent_dim=512,\n",
    "    num_latents=256,\n",
    "    num_images=12,\n",
    "    use_images=True,\n",
    "    use_tabular=True\n",
    ")\n",
    "\n",
    "# Ewaluacja modelu\n",
    "evaluate_model(model, test_json_path=TEST_JSON_PATH, image_dir=IMAGE_DIR, batch_size=16, use_images=True, use_tabular=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
