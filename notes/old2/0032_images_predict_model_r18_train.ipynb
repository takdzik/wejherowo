{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Parametry\n",
    "JSON_PATH = \"../data/train_data.json\"\n",
    "IMAGE_DIR = \"../data/images/\"\n",
    "MODEL_SAVE_DIR = \"../models/\"\n",
    "IMG_HEIGHT, IMG_WIDTH = 140, 100\n",
    "NUM_IMAGES = 12\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 10\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Dataset\n",
    "class CarDataset(Dataset):\n",
    "    def __init__(self, json_path, image_dir, transform=None, num_images=NUM_IMAGES, debug=False):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.num_images = num_images\n",
    "        self.debug = debug\n",
    "\n",
    "        # Wczytaj dane JSON\n",
    "        self.data = pd.read_json(json_path, lines=True)\n",
    "\n",
    "        # Unikalne modele samochodów (mapowanie na klasy)\n",
    "        self.models = {model: idx for idx, model in enumerate(self.data[\"model\"].unique())}\n",
    "\n",
    "        # Filtruj dane, aby uwzględnić tylko oferty z przynajmniej jednym zdjęciem\n",
    "        self.samples = []\n",
    "        for _, row in self.data.iterrows():\n",
    "            car_id = str(row[\"id\"])\n",
    "            has_images = any(\n",
    "                Path(self.image_dir, f\"{car_id}_{i}.jpg\").exists() for i in range(1, self.num_images + 1)\n",
    "            )\n",
    "            if has_images:\n",
    "                self.samples.append({\n",
    "                    \"id\": car_id,\n",
    "                    \"model\": row[\"model\"],  # Klasa modelu samochodu\n",
    "                })\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"Debug: Dataset contains {len(self.samples)} samples.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        car_id = sample[\"id\"]\n",
    "        label = torch.tensor(self.models[sample[\"model\"]], dtype=torch.long)\n",
    "\n",
    "        # Załaduj zdjęcia\n",
    "        images = []\n",
    "        for i in range(1, self.num_images + 1):\n",
    "            image_path = Path(self.image_dir, f\"{car_id}_{i}.jpg\")\n",
    "            if image_path.exists():\n",
    "                img = Image.open(image_path).convert(\"RGB\")\n",
    "                if self.transform:\n",
    "                    img = self.transform(img)\n",
    "                images.append(img)\n",
    "\n",
    "        # Jeśli brakuje zdjęć, powielaj istniejące\n",
    "        while len(images) < self.num_images:\n",
    "            images.append(images[-1])\n",
    "\n",
    "        # Przytnij, jeśli jest za dużo zdjęć\n",
    "        images = images[:self.num_images]\n",
    "        images = torch.stack(images)  # [NUM_IMAGES, C, H, W]\n",
    "\n",
    "        return images, label\n",
    "\n",
    "# Model\n",
    "class CarModelClassifier(nn.Module):\n",
    "    def __init__(self, num_images=NUM_IMAGES, num_classes=10):\n",
    "        super(CarModelClassifier, self).__init__()\n",
    "        # Model bazowy (ResNet18)\n",
    "        self.base_model = models.resnet18(pretrained=True)\n",
    "        self.base_model.fc = nn.Identity()  # Usuń klasyfikator na końcu\n",
    "\n",
    "        # Przetwarzanie obrazów\n",
    "        self.embedding_size = 512  # Rozmiar embeddingu z ResNet18\n",
    "        self.fc = nn.Linear(self.embedding_size, num_classes)\n",
    "\n",
    "def forward(self, x):\n",
    "    # x: [BATCH_SIZE, NUM_IMAGES, C, H, W]\n",
    "    batch_size, num_images, C, H, W = x.size()\n",
    "    \n",
    "    # Przetwarzanie każdego obrazu w ramach jednej oferty\n",
    "    embeddings = []\n",
    "    for i in range(num_images):\n",
    "        img_features = self.base_model(x[:, i, :, :, :])  # Przetwarzanie pojedynczego obrazu\n",
    "        embeddings.append(img_features)\n",
    "    \n",
    "    # Łączenie cech obrazów przy użyciu max pooling\n",
    "    embeddings = torch.stack(embeddings, dim=1)  # [BATCH_SIZE, NUM_IMAGES, EMBEDDING_SIZE]\n",
    "    combined_embedding, _ = embeddings.max(dim=1)  # [BATCH_SIZE, EMBEDDING_SIZE]\n",
    "    \n",
    "    # Klasyfikacja na podstawie połączonych cech\n",
    "    output = self.fc(combined_embedding)  # [BATCH_SIZE, NUM_CLASSES]\n",
    "    return output\n",
    "\n",
    "# Transformacje dla obrazów\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Dataset i DataLoader\n",
    "dataset = CarDataset(JSON_PATH, IMAGE_DIR, transform=transform)\n",
    "train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Model, funkcja kosztu, optymalizator\n",
    "num_classes = len(dataset.models)  # Liczba klas (unikalnych modeli samochodów)\n",
    "model = CarModelClassifier(num_images=NUM_IMAGES, num_classes=num_classes).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Trenowanie\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        # Przewidywania i strata\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Oblicz metryki\n",
    "        epoch_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    accuracy = 100.0 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], Loss: {epoch_loss/len(train_loader):.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Tworzenie katalogu na zapis modelu\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zapis modelu\n",
    "model_path = os.path.join(MODEL_SAVE_DIR, \"car_model_classifier.pth\")\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Model zapisany w: {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
