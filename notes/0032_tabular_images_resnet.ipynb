{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from torchvision.models import ResNet18_Weights\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Parametry\n",
    "TRAIN_JSON_PATH = \"../data/clean_data_train_01.json\"\n",
    "TEST_JSON_PATH = \"../data/clean_data_test_01.json\"\n",
    "IMAGE_DIR = \"../data/images/\"\n",
    "MODEL_SAVE_DIR = \"../models/\"\n",
    "IMG_HEIGHT, IMG_WIDTH = 140, 100\n",
    "NUM_IMAGES = 12\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 15\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Dataset\n",
    "class CarDataset(Dataset):\n",
    "    def __init__(self, json_path, image_dir, transform=None, num_images=12, debug=False):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.num_images = num_images\n",
    "        self.debug = debug\n",
    "\n",
    "        # Wczytaj dane tabelaryczne\n",
    "        self.data = pd.read_json(json_path, lines=True)\n",
    "\n",
    "        # Lista na przefiltrowane próbki\n",
    "        filtered_samples = []\n",
    "\n",
    "        for idx, row in self.data.iterrows():\n",
    "            car_id = str(row[\"id\"])\n",
    "            \n",
    "            # Sprawdź, czy jest przynajmniej jeden obrazek dla tej oferty\n",
    "            has_images = any(\n",
    "                Path(self.image_dir, f\"{car_id}_{i}.jpg\").exists() for i in range(num_images)\n",
    "            )\n",
    "\n",
    "            if has_images:\n",
    "                filtered_samples.append(row)\n",
    "\n",
    "            # Loguj co 1000 wierszy dla debugowania\n",
    "            if debug and idx % 1000 == 0:\n",
    "                print(f\"Processed {idx}/{len(self.data)} rows. Filtered {len(filtered_samples)} valid samples.\")\n",
    "\n",
    "        # Zaktualizuj dane na przefiltrowane próbki\n",
    "        self.data = pd.DataFrame(filtered_samples)\n",
    "\n",
    "        # Usuń `id` i `url` z danych wejściowych modeli\n",
    "        self.features = self.data.drop(columns=[\"id\", \"url\", \"cena\"]).values.astype(float)\n",
    "        self.prices = torch.tensor(self.data[\"cena\"].values, dtype=torch.float32)\n",
    "\n",
    "        # ID do wyszukiwania zdjęć\n",
    "        self.ids = self.data[\"id\"].astype(str).tolist()\n",
    "\n",
    "        # Wczytaj wszystkie obrazy do pamięci RAM\n",
    "        self.cached_images = []\n",
    "        for idx, car_id in enumerate(self.ids):\n",
    "            images = []\n",
    "            for i in range(self.num_images):\n",
    "                image_path = Path(self.image_dir, f\"{car_id}_{i}.jpg\")\n",
    "                if image_path.exists():\n",
    "                    img = Image.open(image_path).convert(\"RGB\")\n",
    "                    if self.transform:\n",
    "                        img = self.transform(img)\n",
    "                    images.append(img)\n",
    "\n",
    "            # Uzupełnij brakujące obrazy, jeśli jest ich za mało\n",
    "            while len(images) < self.num_images:\n",
    "                images.append(images[-1])  # Powielaj brakujące obrazy\n",
    "            images = torch.stack(images)  # [NUM_IMAGES, C, H, W]\n",
    "            self.cached_images.append(images)\n",
    "\n",
    "            # Loguj co 100 załadowanych próbek\n",
    "            if debug and idx % 100 == 0:\n",
    "                print(f\"Loaded {idx}/{len(self.ids)} samples into memory.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.cached_images[idx], torch.tensor(self.features[idx], dtype=torch.float32), self.prices[idx]\n",
    "\n",
    "\n",
    "\n",
    "# Model\n",
    "class MultiModalCarPriceRegressor(nn.Module):\n",
    "    def __init__(self, num_images=12, tabular_input_size=128):\n",
    "        super(MultiModalCarPriceRegressor, self).__init__()\n",
    "        \n",
    "        # Model do ekstrakcji cech z obrazów (ResNet18)\n",
    "        self.base_model = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "        self.base_model.fc = nn.Identity()  # Usuń końcową warstwę klasyfikatora\n",
    "\n",
    "        # Przetwarzanie obrazów\n",
    "        self.image_embedding_size = 512  # Wyjście ResNet18\n",
    "        self.image_fc = nn.Linear(self.image_embedding_size, 128)\n",
    "\n",
    "        # Przetwarzanie danych tabelarycznych\n",
    "        self.tabular_fc = nn.Sequential(\n",
    "            nn.Linear(tabular_input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64)\n",
    "        )\n",
    "\n",
    "        # Warstwa łącząca cechy obrazu i tabelaryczne\n",
    "        self.combined_fc = nn.Sequential(\n",
    "            nn.Linear(128 + 64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)  # Wyjście: przewidywana cena\n",
    "        )\n",
    "\n",
    "    def forward(self, images, tabular_features):\n",
    "        # Przetwarzanie obrazów\n",
    "        batch_size, num_images, C, H, W = images.size()\n",
    "        embeddings = []\n",
    "        for i in range(num_images):\n",
    "            img_features = self.base_model(images[:, i, :, :, :])\n",
    "            embeddings.append(img_features)\n",
    "        embeddings = torch.stack(embeddings, dim=1)\n",
    "        combined_image_features, _ = embeddings.max(dim=1)\n",
    "        combined_image_features = self.image_fc(combined_image_features)\n",
    "\n",
    "        # Przetwarzanie cech tabelarycznych\n",
    "        tabular_features = self.tabular_fc(tabular_features)\n",
    "\n",
    "        # Łączenie cech\n",
    "        combined_features = torch.cat([combined_image_features, tabular_features], dim=1)\n",
    "        output = self.combined_fc(combined_features)\n",
    "        return output.squeeze()\n",
    "\n",
    "\n",
    "# Funkcja kosztu MAPE\n",
    "class MAPE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MAPE, self).__init__()\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        epsilon = 1e-6  # Aby uniknąć dzielenia przez zero\n",
    "        mape = torch.mean(torch.abs((targets - predictions) / (targets + epsilon))) * 100\n",
    "        return mape\n",
    "\n",
    "\n",
    "# Funkcja do ewaluacji\n",
    "def evaluate(model, test_loader, criterion, device=\"cuda\", log_interval=100):\n",
    "    \"\"\"\n",
    "    Ewaluacja modelu na zbiorze testowym.\n",
    "    \n",
    "    Args:\n",
    "        model: Model do ewaluacji.\n",
    "        test_loader: DataLoader zawierający dane testowe.\n",
    "        criterion: Funkcja kosztu (np. MAPE).\n",
    "        device: Urządzenie (domyślnie \"cuda\").\n",
    "        log_interval: Liczba batchy między logami częściowych wyników.\n",
    "    \n",
    "    Returns:\n",
    "        avg_loss: Średnia wartość straty na zbiorze testowym.\n",
    "        avg_mape: Średni błąd procentowy (MAPE) na zbiorze testowym.\n",
    "        y_pred: Lista wszystkich przewidywanych wartości.\n",
    "        y_true: Lista wszystkich rzeczywistych wartości.\n",
    "    \"\"\"\n",
    "    print(\"Starting evaluation...\")\n",
    "    \n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_mape = 0\n",
    "    total_samples = 0\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, tabular_features, prices) in enumerate(test_loader):\n",
    "            images, tabular_features, prices = images.to(device), tabular_features.to(device), prices.to(device)\n",
    "            predictions = model(images, tabular_features)\n",
    "\n",
    "            # Akumulacja strat\n",
    "            loss = criterion(predictions, prices)\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            total_mape += torch.sum(torch.abs((prices - predictions) / (prices + 1e-6))).item() * 100\n",
    "            total_samples += images.size(0)\n",
    "\n",
    "            # Zbieranie przewidywań i wartości rzeczywistych\n",
    "            y_pred.extend(predictions.cpu().tolist())\n",
    "            y_true.extend(prices.cpu().tolist())\n",
    "\n",
    "            # Logowanie częściowych wyników\n",
    "            if (batch_idx + 1) % log_interval == 0:\n",
    "                print(f\"Batch {batch_idx + 1}/{len(test_loader)}:\")\n",
    "                print(f\"  Partial Loss: {loss.item():.4f}, Partial MAPE: {torch.mean(torch.abs((prices - predictions) / (prices + 1e-6))).item() * 100:.2f}%\")\n",
    "    \n",
    "    # Obliczanie średnich metryk\n",
    "    avg_loss = total_loss / total_samples\n",
    "    avg_mape = total_mape / total_samples\n",
    "\n",
    "    print(f\"Evaluation Summary: MAPE: {avg_mape:.2f}%, Average Loss: {avg_loss:.4f}\")\n",
    "    return avg_loss, avg_mape, y_pred, y_true\n",
    "\n",
    "\n",
    "# Transformacje dla obrazów\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "train_dataset = CarDataset(TRAIN_JSON_PATH, IMAGE_DIR, transform=transform, num_images=NUM_IMAGES, debug=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)[:100]\n",
    "\n",
    "# Model, funkcja kosztu, optymalizator\n",
    "model = MultiModalCarPriceRegressor(num_images=NUM_IMAGES, tabular_input_size=train_dataset.features.shape[1]).to(DEVICE)\n",
    "criterion = MAPE()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Trenowanie\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for images, tabular_features, prices in train_loader:\n",
    "        images, tabular_features, prices = images.to(DEVICE), tabular_features.to(DEVICE), prices.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images, tabular_features)\n",
    "        loss = criterion(outputs, prices)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], Loss (MAPE): {epoch_loss/len(train_loader):.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tthaddey\\AppData\\Local\\Temp\\ipykernel_12844\\923809834.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"../models/car_price_regressor_img_tab.pth\", map_location=DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test dataset into memory...\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "aaaa\n",
      "Evaluation Summary: MAPE: 15.05%, Average Loss: 15.0514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15.051362703995553, 15.051362639637162)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ewaluacja\n",
    "\n",
    "test_dataset = CarDataset(TEST_JSON_PATH, IMAGE_DIR, transform=transform, num_images=NUM_IMAGES)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Model, funkcja kosztu, optymalizator\n",
    "model = MultiModalCarPriceRegressor(num_images=NUM_IMAGES, tabular_input_size=test_dataset.features.shape[1]).to(DEVICE)\n",
    "checkpoint = torch.load(\"../models/car_price_regressor_img_tab.pth\", map_location=DEVICE)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "criterion = MAPE()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "avg_loss, avg_mape, y_pred, y_true = evaluate(\n",
    "    model=model,\n",
    "    test_loader=test_loader,\n",
    "    criterion=criterion,\n",
    "    device=DEVICE,\n",
    "    log_interval=100\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
