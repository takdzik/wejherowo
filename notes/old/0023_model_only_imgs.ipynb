{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Ustawienie urządzenia: GPU, jeśli jest dostępne, w przeciwnym razie CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Dataset korzystający jedynie z obrazków\n",
    "class ImageOnlyDataset(Dataset):\n",
    "    def __init__(self, json_file, image_dir, transform=None):\n",
    "        self.data = pd.read_json(json_file, lines=True)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.image_dir, self.data.iloc[idx]['img_local'])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        price = self.data.iloc[idx]['price']\n",
    "        return {\n",
    "            'image': image,\n",
    "            'price': torch.tensor(price, dtype=torch.float32)\n",
    "        }\n",
    "\n",
    "# Model korzystający jedynie z obrazków (CNN)\n",
    "class ImageOnlyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageOnlyModel, self).__init__()\n",
    "        self.cnn = models.resnet18(pretrained=True)\n",
    "        num_features = self.cnn.fc.in_features\n",
    "        self.cnn.fc = nn.Linear(num_features, 1)  # Modyfikacja ostatniej warstwy\n",
    "\n",
    "    def forward(self, image):\n",
    "        return self.cnn(image)\n",
    "\n",
    "# Przygotowanie transformacji obrazu\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Dane treningowe i testowe\n",
    "image_dir = 'data_img'\n",
    "train_json = 'train_data_with_car_type.json'\n",
    "test_json = 'test_data_with_car_type.json'\n",
    "\n",
    "train_dataset = ImageOnlyDataset(json_file=train_json, image_dir=image_dir, transform=transform)\n",
    "test_dataset = ImageOnlyDataset(json_file=test_json, image_dir=image_dir, transform=transform)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Inicjalizacja modelu\n",
    "model = ImageOnlyModel().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Trenowanie modelu\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch in train_dataloader:\n",
    "        images = batch['image'].to(device)\n",
    "        prices = batch['price'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images).squeeze()\n",
    "        loss = criterion(outputs, prices)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(train_dataloader)\n",
    "    epoch_duration = time.time() - start_time\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Duration: {epoch_duration:.2f} seconds\")\n",
    "\n",
    "# Ewaluacja modelu\n",
    "def evaluate_image_model(model, dataloader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            images = batch['image'].to(device)\n",
    "            prices = batch['price'].to(device)\n",
    "            \n",
    "            outputs = model(images).squeeze()\n",
    "            loss = criterion(outputs, prices)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Image Model Test Loss (MSE): {avg_loss:.4f}\")\n",
    "    return avg_loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_image_model(model, test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
