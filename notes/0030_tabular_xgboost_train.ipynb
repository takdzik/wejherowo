{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\studia\\wejherowo_tree\\wejherowo\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import graphs\n",
    "\n",
    "# Wczytanie danych\n",
    "json_file = Path(\"../data/clean_data.json\")\n",
    "df = pd.read_json(json_file, orient='records', lines=True)\n",
    "\n",
    "# Zachowanie kolumny `url` do późniejszego powiązania\n",
    "urls = df[\"url\"]\n",
    "\n",
    "# Przygotowanie danych do treningu\n",
    "df = df.drop(columns=[\"id\", \"lokalizacja\", \"url\"], errors=\"ignore\")\n",
    "X = df.drop(columns=[\"cena\"])  # Wszystkie kolumny poza 'cena' jako cechy\n",
    "X = pd.get_dummies(X, columns=[\"model\", \"rodzaj_paliwa\", \"skrzynia_biegow\", \"naped\", \"typ_nadwozia\", \"kolor\", \"stan_pojazdu\"], drop_first=True)\n",
    "X[['rok_produkcji', 'przebieg', 'pojemnosc_silnika', 'moc_silnika', 'liczba_drzwi', 'liczba_miejsc']] = StandardScaler().fit_transform(X[['rok_produkcji', 'przebieg', 'pojemnosc_silnika', 'moc_silnika', 'liczba_drzwi', 'liczba_miejsc']])\n",
    "y = df[\"cena\"]  # Kolumna 'cena' jako cel\n",
    "\n",
    "# Podział na zbiory treningowe i testowe\n",
    "X_train, X_test, y_train, y_test, urls_train, urls_test = train_test_split(X, y, urls, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wyniki modelu XGBoost:\n",
      "RMSE na zbiorze treningowym: 16148.35\n",
      "RMSE na zbiorze testowym: 23548.17\n",
      "Średnia procentowa rozbieżność na zbiorze treningowym: 13.42%\n",
      "Średnia procentowa rozbieżność na zbiorze testowym: 15.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\studia\\wejherowo_tree\\wejherowo\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\studia\\wejherowo_tree\\wejherowo\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 1. Trenowanie modelu XGBoost\n",
    "model = XGBRegressor(\n",
    "    n_estimators=100,  # Liczba drzew\n",
    "    learning_rate=0.1,  # Szybkość uczenia\n",
    "    max_depth=6,  # Maksymalna głębokość drzewa\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 2. Predykcja na zbiorze treningowym i testowym\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# 3. Obliczanie metryk\n",
    "train_rmse = mean_squared_error(y_train, y_train_pred, squared=False)\n",
    "test_rmse = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "\n",
    "# 4. Obliczanie średniej procentowej rozbieżności\n",
    "train_percentage_error = ((abs(y_train - y_train_pred) / y_train) * 100).mean()\n",
    "test_percentage_error = ((abs(y_test - y_test_pred) / y_test) * 100).mean()\n",
    "\n",
    "# 5. Wyświetlenie wyników\n",
    "print(\"Wyniki modelu XGBoost:\")\n",
    "print(f\"RMSE na zbiorze treningowym: {train_rmse:.2f}\")\n",
    "print(f\"RMSE na zbiorze testowym: {test_rmse:.2f}\")\n",
    "print(f\"Średnia procentowa rozbieżność na zbiorze treningowym: {train_percentage_error:.2f}%\")\n",
    "print(f\"Średnia procentowa rozbieżność na zbiorze testowym: {test_percentage_error:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Funkcja celu dla Optuna\n",
    "def objective(trial):\n",
    "    # Propozycje hiperparametrów\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 5.0),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 10.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.0, 10.0),\n",
    "    }\n",
    "    \n",
    "    # Tworzenie modelu XGBRegressor z zaproponowanymi parametrami\n",
    "    model = XGBRegressor(random_state=42, **params)\n",
    "    \n",
    "    # Trenowanie modelu\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predykcja na zbiorze testowym\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Obliczanie metryki RMSE\n",
    "    rmse = mean_absolute_error(y_test, y_pred)\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "# Tworzenie obiektu Optuna i optymalizacja\n",
    "study = optuna.create_study(direction=\"minimize\")  # Minimalizujemy RMSE\n",
    "study.optimize(objective, n_trials=50)  # Liczba prób\n",
    "\n",
    "# Wyświetlenie najlepszych parametrów i wyniku\n",
    "print(\"Najlepsze parametry:\")\n",
    "print(study.best_params)\n",
    "print(f\"Najlepsze RMSE: {study.best_value:.2f}\")\n",
    "\n",
    "# Trenowanie finalnego modelu z najlepszymi parametrami\n",
    "best_params = study.best_params\n",
    "final_model = XGBRegressor(random_state=42, **best_params)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Ocena modelu\n",
    "y_test_pred = final_model.predict(X_test)\n",
    "\n",
    "# Obliczenie metryk\n",
    "test_rmse = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)  # Średni błąd w PLN\n",
    "test_percentage_error = ((abs(y_test - y_test_pred) / y_test) * 100).mean()\n",
    "\n",
    "# Wyświetlenie wyników\n",
    "print(f\"RMSE na zbiorze testowym: {test_rmse:.2f} PLN\")\n",
    "print(f\"Średnia procentowa rozbieżność na zbiorze testowym: {test_percentage_error:.2f}%\")\n",
    "print(f\"Średni błąd w PLN (MAE): {test_mae:.2f} PLN\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
